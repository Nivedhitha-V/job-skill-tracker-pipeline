{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGFx3pPq8F35",
        "outputId": "2bbd70b6-726a-46fd-daa5-7615b17b17ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Folder structure ready.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folders = [\n",
        "    'data/feed_simulated',\n",
        "    'data/processed',\n",
        "    'logs'\n",
        "]\n",
        "\n",
        "for folder in folders:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "print(\"âœ… Folder structure ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# -------------------------\n",
        "# CONFIGURATION\n",
        "# -------------------------\n",
        "FEED_FOLDER = 'data/feed_simulated'\n",
        "OUTPUT_FOLDER = 'data/processed'\n",
        "LOG_FILE = 'logs/ingestion.log'\n",
        "SKILLS_COLUMN = 'job_skills_cleaned'  # Adjust if needed\n",
        "START_DATE = datetime(2025, 7, 1)  # Simulated start date for day1\n",
        "\n",
        "# -------------------------\n",
        "# SETUP FOLDERS\n",
        "# -------------------------\n",
        "for folder in [FEED_FOLDER, OUTPUT_FOLDER, 'logs']:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# FUNCTIONS\n",
        "# -------------------------\n",
        "\n",
        "def get_next_file():\n",
        "    \"\"\"Get the next unprocessed CSV from feed_simulated/\"\"\"\n",
        "    processed = set()\n",
        "    if os.path.exists(LOG_FILE):\n",
        "        with open(LOG_FILE, 'r') as f:\n",
        "            processed = set(line.strip() for line in f)\n",
        "\n",
        "    all_files = sorted(f for f in os.listdir(FEED_FOLDER) if f.endswith('.csv'))\n",
        "    for file in all_files:\n",
        "        if file not in processed:\n",
        "            return file\n",
        "    return None\n",
        "\n",
        "def extract_top_skills(df):\n",
        "    \"\"\"Extract top 15 skills from the skills column\"\"\"\n",
        "    all_skills = df[SKILLS_COLUMN].dropna().str.split(',').explode().str.strip().str.lower()\n",
        "    top_skills = all_skills.value_counts().head(15).reset_index()\n",
        "    top_skills.columns = ['skill', 'count']\n",
        "    return top_skills\n",
        "\n",
        "def save_output(df, output_path):\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Saved: {output_path}\")\n",
        "\n",
        "def log_file(file_name):\n",
        "    with open(LOG_FILE, 'a') as f:\n",
        "        f.write(file_name + '\\n')\n",
        "\n",
        "def main():\n",
        "    next_file = get_next_file()\n",
        "    if not next_file:\n",
        "        print(\"ğŸ‰ All files processed.\")\n",
        "        return\n",
        "\n",
        "    print(f\"ğŸ“¥ Processing: {next_file}\")\n",
        "    try:\n",
        "        df = pd.read_csv(os.path.join(FEED_FOLDER, next_file))\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error reading {next_file}: {e}\")\n",
        "        return\n",
        "\n",
        "    if SKILLS_COLUMN not in df.columns:\n",
        "        print(f\"âŒ Column '{SKILLS_COLUMN}' not found in data.\")\n",
        "        return\n",
        "\n",
        "    top_skills = extract_top_skills(df)\n",
        "\n",
        "    # ğŸ§  Extract 'day1' from 'day1.csv' and compute the simulated date\n",
        "    day_id = next_file.replace('.csv', '')        # e.g., 'day1'\n",
        "    day_num = int(day_id[3:])                     # e.g., 1\n",
        "    simulated_date = START_DATE + timedelta(days=day_num - 1)\n",
        "\n",
        "    # Add date column for Snowflake\n",
        "    top_skills['date'] = simulated_date.date()\n",
        "\n",
        "    # Save as: skills_day1.csv, skills_day2.csv, etc.\n",
        "    day_id = next_file.replace('.csv', '')  # e.g., 'day1'\n",
        "    output_file = os.path.join(OUTPUT_FOLDER, f'skills_{day_id}.csv')\n",
        "\n",
        "\n",
        "    save_output(top_skills, output_file)\n",
        "\n",
        "    log_file(next_file)\n",
        "    print(f\"ğŸ“ Logged: {next_file}\")\n",
        "\n",
        "# -------------------------\n",
        "# RUN LOOP FOR ALL 10 DAYS\n",
        "# -------------------------\n",
        "if __name__ == '__main__':\n",
        "    for _ in range(10):\n",
        "        main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_42EiR-8OC4",
        "outputId": "806fb941-0fe8-4790-a092-003e19ab59cc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ Processing: day1.csv\n",
            "âœ… Saved: data/processed/skills_day1.csv\n",
            "ğŸ“ Logged: day1.csv\n",
            "ğŸ“¥ Processing: day10.csv\n",
            "âœ… Saved: data/processed/skills_day10.csv\n",
            "ğŸ“ Logged: day10.csv\n",
            "ğŸ“¥ Processing: day2.csv\n",
            "âœ… Saved: data/processed/skills_day2.csv\n",
            "ğŸ“ Logged: day2.csv\n",
            "ğŸ“¥ Processing: day3.csv\n",
            "âœ… Saved: data/processed/skills_day3.csv\n",
            "ğŸ“ Logged: day3.csv\n",
            "ğŸ“¥ Processing: day4.csv\n",
            "âœ… Saved: data/processed/skills_day4.csv\n",
            "ğŸ“ Logged: day4.csv\n",
            "ğŸ“¥ Processing: day5.csv\n",
            "âœ… Saved: data/processed/skills_day5.csv\n",
            "ğŸ“ Logged: day5.csv\n",
            "ğŸ“¥ Processing: day6.csv\n",
            "âœ… Saved: data/processed/skills_day6.csv\n",
            "ğŸ“ Logged: day6.csv\n",
            "ğŸ“¥ Processing: day7.csv\n",
            "âœ… Saved: data/processed/skills_day7.csv\n",
            "ğŸ“ Logged: day7.csv\n",
            "ğŸ“¥ Processing: day8.csv\n",
            "âœ… Saved: data/processed/skills_day8.csv\n",
            "ğŸ“ Logged: day8.csv\n",
            "ğŸ“¥ Processing: day9.csv\n",
            "âœ… Saved: data/processed/skills_day9.csv\n",
            "ğŸ“ Logged: day9.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dd8lvMR8WER",
        "outputId": "af3c2d47-cad8-47b5-f400-53513e0481de"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ‰ All files processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "feed_files = sorted(os.listdir('data/feed_simulated/'))\n",
        "print(\"ğŸ“ Feed Files Found:\", feed_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJs0G17o8nc1",
        "outputId": "407fd45f-9833-4cdd-9474-839969b96481"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Feed Files Found: ['day1.csv', 'day10.csv', 'day2.csv', 'day3.csv', 'day4.csv', 'day5.csv', 'day6.csv', 'day7.csv', 'day8.csv', 'day9.csv']\n"
          ]
        }
      ]
    }
  ]
}